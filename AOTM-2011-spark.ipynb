{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glint-FMPair evaluation on AOTM-2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--conf spark.driver.memory=10G \" + \\\n",
    "    \"--conf spark.driver.extraJavaOptions=-XX:+UseG1GC \" + \\\n",
    "    \"--conf spark.driverEnv.LD_PRELOAD=/opt/cloudera/parcels/mkl/linux/mkl/lib/intel64/libmkl_rt.so \" + \\\n",
    "    \"--conf spark.driverEnv.MKL_VERBOSE=0 \" + \\\n",
    "    \"--jars glint-fmpair/target/scala-2.11/glint-fmpair-assembly-1.0.jar pyspark-shell\"\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from math import log2, ceil\n",
    "\n",
    "from pyspark.ml.linalg import VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import collect_set, udf, col, mean, first\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from glintfmpair import WeightHotEncoderEstimator, WeightHotEncoderModel, GlintFMPair, GlintFMPairModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Glint-FMPair evaluation on AOTM-2011\") \\\n",
    "    .master(\"yarn\") \\\n",
    "    .config(\"spark.submit.deployMode\",\"client\") \\\n",
    "    .config(\"spark.executor.memory\", \"40G\") \\\n",
    "    .config(\"spark.executor.instances\", \"10\") \\\n",
    "    .config(\"spark.executor.cores\", \"10\") \\\n",
    "    .config(\"spark.executorEnv.LD_PRELOAD\",\n",
    "            \"/opt/cloudera/parcels/mkl/linux/mkl/lib/intel64/libmkl_rt.so\") \\\n",
    "    .config(\"spark.executorEnv.MKL_VERBOSE\", \"0\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"-XX:+UseG1GC\") \\\n",
    "    .config(\"spark.jars\", \"glint-fmpair/target/scala-2.11/glint-fmpair-assembly-1.0.jar\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataPath = \"AOTM-2011-train.csv\"\n",
    "valqueryseedsdataPath = \"AOTM-2011-val-queryseeds.csv\"\n",
    "valqueryctxdataPath = \"AOTM-2011-val-queryctx.csv\"\n",
    "valdataPath = \"AOTM-2011-val.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoderModelPaths = [\"AOTM-2011-usercoldstartencoder.model\", \"AOTM-2011-userencoder.model\",\n",
    "                     \"AOTM-2011-itemencoder.model\", \"AOTM-2011-ctxitemencoder.model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameterServerHost=\"10.7.0.105\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadEncoder=False\n",
    "saveEncoder=False\n",
    "loadGlintFMPair=False\n",
    "saveGlintFMPair=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(s, dataPath): \n",
    "    return s.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(dataPath)\n",
    "\n",
    "\n",
    "def loadEncoderModels(modelPaths):\n",
    "    return tuple(WeightHotEncoderModel.load(modelPath) for modelPath in modelPaths)\n",
    "\n",
    "\n",
    "def fitEncoderModels(data):\n",
    "    \n",
    "    userColdStartGroupCols = [\"pid\"]\n",
    "    userColdStartCols = [\"traid\"]\n",
    "    userColdStartWeights = [1.0]\n",
    "    userColdStartEncoderModel = WeightHotEncoderEstimator(\n",
    "        weights=userColdStartWeights, inputCols=userColdStartCols,\n",
    "        outputCols=[c + \"_cold_encoded\" for c in userColdStartCols],\n",
    "        groupCols=userColdStartGroupCols, groupWeighting=\"sqrt\"\n",
    "    ).fit(data)\n",
    "    \n",
    "    # dropLast, missing user features are simply ignored, no problem for ranking\n",
    "    userCols = [\"pid\", \"userid\", \"category\", \"pyear\"]\n",
    "    userWeights = [1.0, 1.0, 1.0, 0.125]\n",
    "    userEncoderModel = WeightHotEncoderEstimator(\n",
    "        weights=userWeights, inputCols=userCols,\n",
    "        outputCols=[c + \"_encoded\" for c in userCols], dropLast=True\n",
    "    ).fit(data)\n",
    "    \n",
    "    # missing item features are mapped to the missing feature index\n",
    "    itemCols = [\"traid\", \"albid\", \"artid\", \"year\"]\n",
    "    itemWeights = [1.0, 1.0, 1.0, 0.125]\n",
    "    itemEncoderModel = WeightHotEncoderEstimator(\n",
    "        weights=itemWeights, inputCols=itemCols,\n",
    "        outputCols=[c + \"_encoded\" for c in itemCols], dropLast=False\n",
    "    ).fit(data)\n",
    "\n",
    "    # dropLast, missing user features are simply ignored, no problem for ranking\n",
    "    ctxitemCols = [\"prev_traid\", \"prev_albid\", \"prev_artid\", \"prev_year\"]\n",
    "    ctxitemWeights = [0.25 * w for w in itemWeights]\n",
    "    ctxitemEncoderModel = itemEncoderModel.copy({\n",
    "        itemEncoderModel.weights: ctxitemWeights,\n",
    "        itemEncoderModel.inputCols: ctxitemCols,\n",
    "        itemEncoderModel.outputCols: [c + \"_encoded\" for c in ctxitemCols],\n",
    "        itemEncoderModel.dropLast: True,\n",
    "        itemEncoderModel.handleInvalid: \"keep\"\n",
    "    })\n",
    "    \n",
    "    return userColdStartEncoderModel, userEncoderModel, itemEncoderModel, ctxitemEncoderModel\n",
    "\n",
    "\n",
    "def resizeVector(sizeVector, resizeVector):\n",
    "    resizeVector.size = sizeVector.size\n",
    "    return resizeVector\n",
    "\n",
    "\n",
    "resizeVectorUdf = udf(resizeVector, VectorUDT())\n",
    "\n",
    "    \n",
    "def toFeatures(data, models, queryctxData=None, sharedItemFeatures=False,\n",
    "               allUserColdStartWeights=[1.0],\n",
    "               userColdStartWeighting=\"sqrt\",\n",
    "               allUserWeights=[1.0, 1.0, 1.0, 0.125],\n",
    "               allCtxitemWeights=[0.25, 0.25, 0.25, 0.25*0.125],\n",
    "               allItemWeights=[1.0, 1.0, 1.0, 0.125],\n",
    "               coldStartUserCols=[],\n",
    "               userCols=[\"pid\", \"userid\", \"category\", \"pyear\"],\n",
    "               ctxitemCols=[\"prev_traid\", \"prev_albid\", \"prev_artid\", \"prev_year\"],\n",
    "               itemCols=[\"traid\", \"albid\", \"artid\", \"year\"]):\n",
    "    \n",
    "    userColdStartEncoderModel, userEncoderModel, itemEncoderModel, ctxitemEncoderModel = models\n",
    "    \n",
    "    encodedColdStartUserCols = [c + \"_cold_encoded\" for c in coldStartUserCols]\n",
    "    encodedUserCols = [c + \"_encoded\" for c in userCols]\n",
    "    encodedItemCols = [c + \"_encoded\" for c in itemCols]\n",
    "    encodedCtxitemCols = [c + \"_encoded\" for c in ctxitemCols]\n",
    "    \n",
    "    # hot encode\n",
    "    if coldStartUserCols:\n",
    "        data = userColdStartEncoderModel \\\n",
    "            .setWeights(allUserColdStartWeights) \\\n",
    "            .setGroupWeighting(userColdStartWeighting) \\\n",
    "            .transform(data)\n",
    "    \n",
    "    if queryctxData:\n",
    "        firstColdStartUserCols = [first(c).alias(c) for c in encodedColdStartUserCols]\n",
    "        data = data.groupBy(\"pid\") \\\n",
    "            .agg(collect_set(\"traid\").alias(\"filteritemids\"), *firstColdStartUserCols) \\\n",
    "            .select(\"pid\", \"filteritemids\", *encodedColdStartUserCols) \\\n",
    "            .join(queryctxData, \"pid\")\n",
    "    else:\n",
    "        data = itemEncoderModel.setWeights(allItemWeights).transform(data)\n",
    "    \n",
    "    if userCols: \n",
    "        data = userEncoderModel.setWeights(allUserWeights).transform(data)\n",
    "        \n",
    "    if ctxitemCols:\n",
    "        data = ctxitemEncoderModel.setWeights(allCtxitemWeights).transform(data)\n",
    "\n",
    "    # assemble feature vectors of required hot-encoded columns into combined feature vectors\n",
    "    userInputCols = encodedCtxitemCols + encodedColdStartUserCols + encodedUserCols\n",
    "    userAssembler = VectorAssembler(inputCols=userInputCols, outputCol=\"userctxfeatures\")\n",
    "    data = userAssembler.transform(data)\n",
    "\n",
    "    if not queryctxData:\n",
    "        itemInputCols = encodedItemCols\n",
    "        itemAssembler = VectorAssembler(inputCols=itemInputCols, outputCol=\"itemfeatures\")\n",
    "        data = itemAssembler.transform(data)\n",
    "\n",
    "    # rename columns to Glint-FMPair names\n",
    "    cols = [col(\"userctxfeatures\"), col(\"pid\").alias(\"userid\")]\n",
    "    \n",
    "    if queryctxData:\n",
    "        cols += [col(\"filteritemids\")]\n",
    "    elif sharedItemFeatures:\n",
    "        cols += [resizeVectorUdf(col(\"userctxfeatures\"), col(\"itemfeatures\")).alias(\"itemfeatures\"), \n",
    "                 col(\"traid\").alias(\"itemid\")]\n",
    "    else:\n",
    "        cols += [col(\"itemfeatures\"), col(\"traid\").alias(\"itemid\")]\n",
    "    \n",
    "    if \"albid\" in itemCols:\n",
    "        cols += [col(\"albid\")]\n",
    "    \n",
    "    if \"artid\" in itemCols:\n",
    "        cols += [col(\"artid\")]\n",
    "    \n",
    "    return data.select(*cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = loadData(spark, traindataPath)\n",
    "\n",
    "valdata = loadData(spark, valdataPath) \\\n",
    "    .select(col(\"pid\").alias(\"userid\"), col(\"traid\").alias(\"itemid\"))\n",
    "\n",
    "valqueryseedsdata = loadData(spark, valqueryseedsdataPath)\n",
    "valqueryctxdata = loadData(spark, valqueryctxdataPath)\n",
    "\n",
    "if loadEncoder:\n",
    "    encoderModels = loadEncoderModels(encoderModelPaths) \n",
    "else:\n",
    "    encoderModels = fitEncoderModels(traindata)\n",
    "    if saveEncoder:\n",
    "        for model, modelPath in zip(encoderModels, encoderModelPaths):\n",
    "            model.save(modelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(itemid, recs):\n",
    "    return sum(1.0 / log2(i + 2) if rec[\"itemid\"] == itemid else 0.0\n",
    "               for i, rec in enumerate(recs))\n",
    "\n",
    "def hitRate(itemid, recs):\n",
    "    return 1.0 if recs[0][\"itemid\"] == itemid else 0\n",
    "\n",
    "\n",
    "dcgUdf = udf(dcg)\n",
    "hitRateUdf = udf(hitRate)\n",
    "\n",
    "\n",
    "def evaluateModel(queryfeatures, evaldata, model):\n",
    "    recdata = model.recommendForUserSubset(queryfeatures, 500).join(evaldata, \"userid\")\n",
    "    scores = recdata \\\n",
    "        .select(hitRateUdf(\"itemid\", \"recommendations\").alias(\"hitRate\"), \\\n",
    "                dcgUdf(\"itemid\", \"recommendations\").alias(\"dcg\")) \\\n",
    "        .select(mean(col(\"hitRate\")), mean(col(\"dcg\"))) \\\n",
    "        .first()\n",
    "    \n",
    "    hitRate = scores[0]\n",
    "    ndcg = scores[1]\n",
    "    return hitRate, ndcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "211.94682s fit time\n",
      "0.009000 hit rate\n",
      "0.067102 NDCG\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = toFeatures(traindata, encoderModels,\n",
    "                           userCols=[\"pid\"], itemCols=[\"traid\"], ctxitemCols=[])\n",
    "valqueryFeatures = toFeatures(valqueryseedsdata, encoderModels,\n",
    "                              queryctxData=valqueryctxdata,\n",
    "                              userCols=[\"pid\"], ctxitemCols=[])\n",
    "\n",
    "modelPath = \"AOTM-2011.model\"\n",
    "if loadGlintFMPair:\n",
    "    model = GlintFMPairModel.load(modelPath, parameterServerHost=parameterServerHost)\n",
    "    with open(modelPath, \"rb\") as f:\n",
    "        fitTime = pickle.load(f)\n",
    "else:\n",
    "    fitStart = time.time()\n",
    "    model = GlintFMPair(\n",
    "        batchSize=256, stepSize=1.0, linearReg=0.03, factorsReg=0.01, numDims=150,\n",
    "        parameterServerHost=parameterServerHost, numParameterServers=3, maxIter=100,\n",
    "        samplingCol=\"\", sampler=\"crossbatch\", filterItemsCol=\"filteritemids\"\n",
    "    ).fit(trainFeatures)\n",
    "    fitEnd = time.time()\n",
    "    fitTime = fitEnd - fitStart\n",
    "    \n",
    "    if saveGlintFMPair:\n",
    "        model.save(modelPath)\n",
    "        with open(modelPath, \"wb\") as f:\n",
    "            pickle.dump(fitTime, f)\n",
    "            \n",
    "hitRate, ndcg = evaluateModel(valqueryFeatures, valdata, model)\n",
    "model.destroy()\n",
    "print(\"{:.5f}s fit time\\n{:.6f} hit rate\\n{:.6f} NDCG\".format(fitTime, hitRate, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259.30806s fit time\n",
      "0.015000 hit rate\n",
      "0.086630 NDCG\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = toFeatures(traindata, encoderModels)\n",
    "valqueryFeatures = toFeatures(valqueryseedsdata, encoderModels,\n",
    "                              queryctxData=valqueryctxdata)\n",
    "\n",
    "modelPath = \"AOTM-2011-prevall.model\"\n",
    "if loadGlintFMPair:\n",
    "    model = GlintFMPairModel.load(modelPath, parameterServerHost=parameterServerHost)\n",
    "    with open(modelPath, \"rb\") as f:\n",
    "        fitTime = pickle.load(f)\n",
    "else:\n",
    "    fitStart = time.time()\n",
    "    model = GlintFMPair(\n",
    "        batchSize=256, stepSize=1.0, linearReg=0.03, factorsReg=0.001, numDims=150,\n",
    "        parameterServerHost=parameterServerHost, numParameterServers=3, maxIter=100,\n",
    "        samplingCol=\"\", sampler=\"crossbatch\", filterItemsCol=\"filteritemids\"\n",
    "    ).fit(trainFeatures)\n",
    "    fitEnd = time.time()\n",
    "    fitTime = fitEnd - fitStart\n",
    "    \n",
    "    if saveGlintFMPair:\n",
    "        model.save(modelPath)\n",
    "        with open(modelPath, \"wb\") as f:\n",
    "            pickle.dump(fitTime, f)\n",
    "            \n",
    "hitRate, ndcg = evaluateModel(valqueryFeatures, valdata, model)\n",
    "model.destroy()\n",
    "print(\"{:.5f}s fit time\\n{:.6f} hit rate\\n{:.6f} NDCG\".format(fitTime, hitRate, ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390.35133s fit time\n",
      "0.011000 hit rate\n",
      "0.089183 NDCG\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = toFeatures(traindata, encoderModels,\n",
    "                           sharedItemFeatures=True,\n",
    "                           coldStartUserCols=[\"traid\"],\n",
    "                           userCols=[\"userid\", \"category\", \"pyear\"])\n",
    "valqueryFeatures = toFeatures(valqueryseedsdata, encoderModels,\n",
    "                              queryctxData=valqueryctxdata,\n",
    "                              sharedItemFeatures=True,\n",
    "                              coldStartUserCols=[\"traid\"],\n",
    "                              userCols=[\"userid\", \"category\", \"pyear\"])\n",
    "\n",
    "modelPath = \"AOTM-2011-cold-prevall.model\"\n",
    "if loadGlintFMPair:\n",
    "    model = GlintFMPairModel.load(modelPath, parameterServerHost=parameterServerHost)\n",
    "    with open(modelPath, \"rb\") as f:\n",
    "        fitTime = pickle.load(f)\n",
    "else:\n",
    "    fitStart = time.time()\n",
    "    model = GlintFMPair(\n",
    "        batchSize=256, stepSize=1.0, linearReg=0.03, factorsReg=0.001, numDims=150,\n",
    "        parameterServerHost=parameterServerHost, numParameterServers=3, maxIter=100,\n",
    "        samplingCol=\"\", sampler=\"crossbatch\", filterItemsCol=\"filteritemids\"\n",
    "    ).fit(trainFeatures)\n",
    "    fitEnd = time.time()\n",
    "    fitTime = fitEnd - fitStart\n",
    "    \n",
    "    if saveGlintFMPair:\n",
    "        model.save(modelPath)\n",
    "        with open(modelPath, \"wb\") as f:\n",
    "            pickle.dump(fitTime, f)\n",
    "\n",
    "hitRate, ndcg = evaluateModel(valqueryFeatures, valdata, model)\n",
    "model.destroy()\n",
    "print(\"{:.5f}s fit time\\n{:.6f} hit rate\\n{:.6f} NDCG\".format(fitTime, hitRate, ndcg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another run where the data is cached and preprocessing not counted towards fit time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328.33092s fit time\n",
      "0.009000 hit rate\n",
      "0.087948 NDCG\n"
     ]
    }
   ],
   "source": [
    "trainFeatures = toFeatures(traindata, encoderModels,\n",
    "                           sharedItemFeatures=True,\n",
    "                           coldStartUserCols=[\"traid\"],\n",
    "                           userCols=[\"userid\", \"category\", \"pyear\"]).coalesce(100).cache()\n",
    "valqueryFeatures = toFeatures(valqueryseedsdata, encoderModels,\n",
    "                              queryctxData=valqueryctxdata,\n",
    "                              sharedItemFeatures=True,\n",
    "                              coldStartUserCols=[\"traid\"],\n",
    "                              userCols=[\"userid\", \"category\", \"pyear\"])\n",
    "\n",
    "trainFeatures.count()\n",
    "\n",
    "fitStart = time.time()\n",
    "model = GlintFMPair(\n",
    "    batchSize=256, stepSize=1.0, linearReg=0.03, factorsReg=0.001, numDims=150,\n",
    "    parameterServerHost=parameterServerHost, numParameterServers=3, maxIter=100,\n",
    "    samplingCol=\"\", sampler=\"crossbatch\", filterItemsCol=\"filteritemids\"\n",
    ").fit(trainFeatures)\n",
    "fitEnd = time.time()\n",
    "fitTime = fitEnd - fitStart\n",
    "\n",
    "hitRate, ndcg = evaluateModel(valqueryFeatures, valdata, model)\n",
    "model.destroy()\n",
    "print(\"{:.5f}s fit time\\n{:.6f} hit rate\\n{:.6f} NDCG\".format(fitTime, hitRate, ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark3",
   "language": "python",
   "name": "pyspark3kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
